{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95dec3e-e7af-405b-898c-37f2f676b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def classify_tweets(api_key, tweets_df, output_file=\"classified_tweets.csv\"):\n",
    "    openai.api_key = api_key\n",
    "    \n",
    "    def create_prompt(candidate_name, party_name, tweets):\n",
    "        tweets_text = \"\\n\".join([f\"{idx+1}: {text}\" for idx, text in enumerate(tweets)])\n",
    "        prompt = (f\"Classify these tweets of the presidential candidate {candidate_name} of the party {party_name} \"\n",
    "                  \"with the following scores:\\n\"\n",
    "                  \"1: only if it is self-referential or makes emphasis on the individual qualities of the candidate\\n\"\n",
    "                  \"-1: only if it makes emphasis on the party or political movement the candidate belongs to.\\n\"\n",
    "                  \"0: if it does not belong to any of the previous categories\\n\\n\"\n",
    "                  \"Only return the tweet number and classification score. No additional text.\\n\\n\"\n",
    "                  f\"{tweets_text}\")\n",
    "        return prompt\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    grouped = tweets_df.groupby(['candidate_name', 'party_name'])\n",
    "    \n",
    "    for (candidate_name, party_name), group in grouped:\n",
    "        tweets = group['text'].tolist()\n",
    "        tweet_ids = group['id'].tolist()\n",
    "        total_tweets = len(tweets)\n",
    "        \n",
    "        for i in range(0, total_tweets, 200):\n",
    "            tweet_batch = tweets[i:i + 200]\n",
    "            id_batch = tweet_ids[i:i + 200]\n",
    "            \n",
    "            prompt = create_prompt(candidate_name, party_name, tweet_batch)\n",
    "            \n",
    "            success = False\n",
    "            while not success:\n",
    "                try:\n",
    "                    response = openai.ChatCompletion.create(\n",
    "                        model=\"gpt-4o-mini\",  # Use the appropriate model\n",
    "                        messages=[\n",
    "                            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                            {\"role\": \"user\", \"content\": prompt}\n",
    "                        ],\n",
    "                        temperature=0,  # Ensures the output is deterministic and to the point\n",
    "                        max_tokens=1000  # Adjust based on expected output size\n",
    "                    )\n",
    "                    classifications = response['choices'][0]['message']['content'].strip().split(\"\\n\")\n",
    "                    \n",
    "                    for j, classification in enumerate(classifications):\n",
    "                        classification_score = int(classification.split(\":\")[-1].strip())\n",
    "                        results.append({\n",
    "                            \"ID\": id_batch[j],\n",
    "                            \"Classification Score\": classification_score\n",
    "                        })\n",
    "                    \n",
    "                    success = True  # If the request was successful, exit the loop\n",
    "\n",
    "                except openai.error.RateLimitError as e:\n",
    "                    error_message = str(e)\n",
    "                    print(f\"Rate limit reached: {e}. Waiting for 60 seconds before retrying...\")\n",
    "                    \n",
    "                    # Check if the error message indicates a daily limit reached\n",
    "                    if \"Rate limit reached for gpt-4o-mini in organization\" in error_message and \"on requests per day\" in error_message:\n",
    "                        print(\"Daily request limit reached. Saving the data and stopping the process.\")\n",
    "                        pd.DataFrame(results).to_csv(output_file, index=False)\n",
    "                        return pd.DataFrame(results)  # Return what has been processed so far\n",
    "                    \n",
    "                    time.sleep(60)  # Wait before retrying\n",
    "\n",
    "                except openai.error.APIConnectionError as e:\n",
    "                    print(f\"API connection error: {e}. Waiting for 10 seconds before retrying...\")\n",
    "                    time.sleep(10)  # Wait before retrying\n",
    "\n",
    "                except openai.error.APIError as e:\n",
    "                    print(f\"API error: {e}. Waiting for 10 seconds before retrying...\")\n",
    "                    time.sleep(10)  # Wait before retrying\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Unexpected error: {e}. Waiting for 10 seconds before retrying...\")\n",
    "                    time.sleep(10)  # Wait before retrying\n",
    "\n",
    "    print(\"Classification process completed successfully.\")\n",
    "    pd.DataFrame(results).to_csv(output_file, index=False)\n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb265494-ed60-4995-9bfb-899df1947f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit reached: Rate limit reached for gpt-4o-mini in organization org-HXKpLejFknNaY6q9ck33dmNV on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.. Waiting for 60 seconds before retrying...\n",
      "Classification process completed successfully.\n"
     ]
    }
   ],
   "source": [
    "api_key = \"\"\n",
    "tweets_df = pd.read_csv(\"/Users/Fede/Desktop/Twitter_data.csv\")\n",
    "result_df = classify_tweets(api_key, tweets_df)\n",
    "result_df.to_csv(\"/Users/Fede/Desktop/classified_tweets.csv\", index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb69c2e-8480-41e4-bba9-bdd93bbe9b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6cc394fc-2929-4f73-9c5a-919448d22947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Classification Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>492</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>483</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>484</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>486</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Classification Score\n",
       "0    488                     0\n",
       "1    489                     1\n",
       "2    490                     0\n",
       "3    491                     0\n",
       "4    492                     1\n",
       "..   ...                   ...\n",
       "436  483                    -1\n",
       "437  484                     0\n",
       "438  485                     0\n",
       "439  486                    -1\n",
       "440  487                     0\n",
       "\n",
       "[441 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
